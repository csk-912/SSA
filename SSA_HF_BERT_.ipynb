{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSA_HF_BERT .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c88bfe1e7e34a2dbb963b8dc84135d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4b2b4b6823849f885c76e599936fb66",
              "IPY_MODEL_28ce04be0aa34815a8f4dad2e3889916",
              "IPY_MODEL_25db5231d44248c084ab94aff58e98a0"
            ],
            "layout": "IPY_MODEL_2eeb788b0360458fa4fa8484edafbdc0"
          }
        },
        "a4b2b4b6823849f885c76e599936fb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6dbf880689d4d59af3cfd23a696b592",
            "placeholder": "​",
            "style": "IPY_MODEL_05c8601b889f4dc9a8569e97f6ca1ab6",
            "value": "Downloading: 100%"
          }
        },
        "28ce04be0aa34815a8f4dad2e3889916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688b390cf2e940939342d31d0ba4bebf",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_001ad7132efd470c83b8071b2f6f1bd4",
            "value": 231508
          }
        },
        "25db5231d44248c084ab94aff58e98a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a824b5e81c304964aabb17cc21830a8b",
            "placeholder": "​",
            "style": "IPY_MODEL_2c03168979b8413599e288905e733c50",
            "value": " 232k/232k [00:00&lt;00:00, 1.29MB/s]"
          }
        },
        "2eeb788b0360458fa4fa8484edafbdc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6dbf880689d4d59af3cfd23a696b592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c8601b889f4dc9a8569e97f6ca1ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "688b390cf2e940939342d31d0ba4bebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "001ad7132efd470c83b8071b2f6f1bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a824b5e81c304964aabb17cc21830a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c03168979b8413599e288905e733c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5b11b111f9f403a9d7f846fc9b3f10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4718a76e10d440f6a25b922dab5a76fb",
              "IPY_MODEL_fa2a0b6e800343459266e09f2ad61277",
              "IPY_MODEL_d87e8b82ac9f49f3aacd8ca7227f2713"
            ],
            "layout": "IPY_MODEL_5876adb260b24dbdab6ec4a2e58ffc46"
          }
        },
        "4718a76e10d440f6a25b922dab5a76fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb436f298ad49f4b7f0e51ff3010fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_d0021190cac5417d969dbec7c4446c2a",
            "value": "Downloading: 100%"
          }
        },
        "fa2a0b6e800343459266e09f2ad61277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6be597dfeb8463c8cd47de177a21dae",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76537851e78c4071a6f90418b29ae8ae",
            "value": 433
          }
        },
        "d87e8b82ac9f49f3aacd8ca7227f2713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4281172bebc24ae4ba526060fd737196",
            "placeholder": "​",
            "style": "IPY_MODEL_e7fa1626379f48838945160f6976b225",
            "value": " 433/433 [00:00&lt;00:00, 8.82kB/s]"
          }
        },
        "5876adb260b24dbdab6ec4a2e58ffc46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb436f298ad49f4b7f0e51ff3010fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0021190cac5417d969dbec7c4446c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6be597dfeb8463c8cd47de177a21dae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76537851e78c4071a6f90418b29ae8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4281172bebc24ae4ba526060fd737196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7fa1626379f48838945160f6976b225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d57f6499dc34740b3334ad40970e4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce83f397ff9b4a4cb6c8aa6ee10166bb",
              "IPY_MODEL_78246bf8c12147ba9193436944cb0c1d",
              "IPY_MODEL_04d9b3f913cf44bf81ae8e8b36430e05"
            ],
            "layout": "IPY_MODEL_bbc79c7d00474e25b83759ecd97808ff"
          }
        },
        "ce83f397ff9b4a4cb6c8aa6ee10166bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8efe0cb9c1da492aaba76ab19d977a92",
            "placeholder": "​",
            "style": "IPY_MODEL_e68041c8c5044bfdb190c16c0fa6d451",
            "value": "Downloading: 100%"
          }
        },
        "78246bf8c12147ba9193436944cb0c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fc1796ced9e46cf8981c396690886c7",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_315ed0f5d173490e98b4d28aca6686d2",
            "value": 440473133
          }
        },
        "04d9b3f913cf44bf81ae8e8b36430e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6b23f121f847adb95b5aae915d3d98",
            "placeholder": "​",
            "style": "IPY_MODEL_aea634c4c50b48caa10bbbe9ce299ba2",
            "value": " 440M/440M [00:25&lt;00:00, 13.6MB/s]"
          }
        },
        "bbc79c7d00474e25b83759ecd97808ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efe0cb9c1da492aaba76ab19d977a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68041c8c5044bfdb190c16c0fa6d451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fc1796ced9e46cf8981c396690886c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315ed0f5d173490e98b4d28aca6686d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b6b23f121f847adb95b5aae915d3d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea634c4c50b48caa10bbbe9ce299ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install transformers module\n",
        "!pip install transformers==3.1.0\n",
        "!pip install ftfy"
      ],
      "metadata": {
        "id": "FOAIeWOHBn2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c362d831-64b2-47c2-a0b8-75c44597a266"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.1.0\n",
            "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 593 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 604 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 624 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 655 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 665 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 686 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 696 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 727 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 747 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 757 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 778 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 788 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 808 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 819 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 829 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 839 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 849 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 860 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 870 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 880 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 884 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.21.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 22.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 26.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.1.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.1.0\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "import argparse\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from ftfy import fix_text\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n"
      ],
      "metadata": {
        "id": "8X6EqTyBwXFo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfWx5vg2EGg3",
        "outputId": "7a92a969-ae1e-4f84-a68b-c00b8c33572f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train.json', encoding='utf-8') as inputfile:\n",
        "    df = pd.read_json(inputfile,lines = True)"
      ],
      "metadata": {
        "id": "nc9GW6YbADLF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVfyFSfx1VDe",
        "outputId": "3c1e964a-2a99-48d0-9717-d4245bae961c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sent_id', 'text', 'sources', 'targets', 'expressions'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cols in df:\n",
        "  print(cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYieD6pP0v8A",
        "outputId": "cf8cad44-67d5-464e-f84b-8bc5f1f5b073"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_id\n",
            "text\n",
            "sources\n",
            "targets\n",
            "expressions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df['text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SshHIdb9zkQ",
        "outputId": "4205efe1-2176-459d-b029-1f77c2620639"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#preprocessing training data\n",
        "import csv\n",
        "max_len_sent = 0\n",
        "# Converting json file to csv file\n",
        "# columns of the new csv file\n",
        "\"\"\"\n",
        "Each sentence is tokenized into words and in turn each word is labelled.\n",
        "labels are shown in the following cells\n",
        "A slight modification to the dataset is done for our convinience.\n",
        "\"\"\"\n",
        "header = [\"Sentence #\", \"Word\", \"Tag\"]\n",
        "with open('labeled_words.csv', 'w', encoding='UTF8') as preproc_csv:\n",
        "  # writer pointer to write into csv file\n",
        "    writer = csv.writer(preproc_csv)\n",
        "    writer.writerow(header)\n",
        "    for i in range(0, len(df)):\n",
        "      # Number of words in each sentence\n",
        "        n_words = len(df['text'][i])\n",
        "        max_len_sent = max(max_len_sent,n_words)\n",
        "        if(n_words == 0):\n",
        "          # If there is null string\n",
        "            continue\n",
        "        for j in range(0, n_words):\n",
        "            # Unlabelled token\n",
        "            token = \"O\"\n",
        "            # Assigning labels\n",
        "            if(len(df['sources'][i][j]) > 1):\n",
        "                token = df['sources'][i][j]\n",
        "            elif(len(df['targets'][i][j]) > 1):\n",
        "                token = df['targets'][i][j]\n",
        "            elif(len(df['expressions'][i][j]) > 1):\n",
        "                token = df['expressions'][i][j]\n",
        "            sentence_no = \"Sentence: \" + str(i)\n",
        "            # Appending each row to the csv file\n",
        "            row = []\n",
        "            row.append(sentence_no)\n",
        "            row.append(df['text'][i][j])\n",
        "            row.append(token)\n",
        "            writer.writerow(row)\n"
      ],
      "metadata": {
        "id": "A_Q9xfvDx1bv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_len_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WuwE74D93Ps",
        "outputId": "06b4f619-9851-4272-c40d-e4d201b1b2fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('labeled_words.csv', encoding='UTF-8')\n",
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6JxE1qSvvscQ",
        "outputId": "54097199-d126-49fe-bac7-eaa50f01e452"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #         Word Tag\n",
              "0  Sentence: 0  Experienced   O\n",
              "1  Sentence: 0        staff   O\n",
              "2  Sentence: 0          and   O\n",
              "3  Sentence: 0          had   O\n",
              "4  Sentence: 0            a   O\n",
              "5  Sentence: 0    memorable   O\n",
              "6  Sentence: 0         stay   O\n",
              "7  Sentence: 1        India   O\n",
              "8  Sentence: 1           as   O\n",
              "9  Sentence: 1            a   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18b2c92e-985b-4936-a79b-98b5b8234c47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>Experienced</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>staff</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>had</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>memorable</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>stay</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>India</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>as</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b2c92e-985b-4936-a79b-98b5b8234c47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18b2c92e-985b-4936-a79b-98b5b8234c47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18b2c92e-985b-4936-a79b-98b5b8234c47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of words in the whole train.json file\n",
        "data.count()"
      ],
      "metadata": {
        "id": "-uZQomW0J93Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade42e82-b9ed-478f-9486-317a91f8bbed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    25677\n",
              "Word          25677\n",
              "Tag           25677\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of labels which were discussed earlier\n",
        "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
        "# Frequency of each tags\n",
        "frequencies = data.Tag.value_counts()\n",
        "frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INpwY2qkE4Cl",
        "outputId": "df9e3701-7971-4d07-be96-5047b68fc5c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tags: 11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O                  15249\n",
              "I-exp-Positive      2125\n",
              "B-exp-Positive      1991\n",
              "B-targ-Positive     1566\n",
              "I-exp-Negative      1462\n",
              "I-targ-Positive     1143\n",
              "B-exp-Negative       781\n",
              "B-targ-Negative      581\n",
              "I-targ-Negative      576\n",
              "B-holder             201\n",
              "I-holder               2\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "# Dictionary of labels\n",
        "labels_to_ids = {}\n",
        "ids_to_labels = {}\n",
        "for label in data.Tag:\n",
        "  if label not in labels_to_ids.keys():\n",
        "    ids_to_labels[i] = label\n",
        "    labels_to_ids[label] = i\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "QiFPbVwv4wiI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DegiiTp5Y5H",
        "outputId": "3c6defc0-81f0-4102-d35b-168bc7f37f18"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-exp-Positive',\n",
              " 2: 'I-exp-Positive',\n",
              " 3: 'B-targ-Positive',\n",
              " 4: 'I-targ-Positive',\n",
              " 5: 'B-holder',\n",
              " 6: 'B-exp-Negative',\n",
              " 7: 'I-exp-Negative',\n",
              " 8: 'B-targ-Negative',\n",
              " 9: 'I-targ-Negative',\n",
              " 10: 'I-holder'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
        "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "5krNYYr6_oe3",
        "outputId": "03e79b46-10e4-426d-fbf3-a957bf66c6f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #         Word Tag  \\\n",
              "0  Sentence: 0  Experienced   O   \n",
              "1  Sentence: 0        staff   O   \n",
              "2  Sentence: 0          and   O   \n",
              "3  Sentence: 0          had   O   \n",
              "4  Sentence: 0            a   O   \n",
              "5  Sentence: 0    memorable   O   \n",
              "6  Sentence: 0         stay   O   \n",
              "7  Sentence: 1        India   O   \n",
              "8  Sentence: 1           as   O   \n",
              "9  Sentence: 1            a   O   \n",
              "\n",
              "                                            sentence  \\\n",
              "0         Experienced staff and had a memorable stay   \n",
              "1         Experienced staff and had a memorable stay   \n",
              "2         Experienced staff and had a memorable stay   \n",
              "3         Experienced staff and had a memorable stay   \n",
              "4         Experienced staff and had a memorable stay   \n",
              "5         Experienced staff and had a memorable stay   \n",
              "6         Experienced staff and had a memorable stay   \n",
              "7  India as a country has always fascinated me an...   \n",
              "8  India as a country has always fascinated me an...   \n",
              "9  India as a country has always fascinated me an...   \n",
              "\n",
              "                                         word_labels  \n",
              "0                                      O,O,O,O,O,O,O  \n",
              "1                                      O,O,O,O,O,O,O  \n",
              "2                                      O,O,O,O,O,O,O  \n",
              "3                                      O,O,O,O,O,O,O  \n",
              "4                                      O,O,O,O,O,O,O  \n",
              "5                                      O,O,O,O,O,O,O  \n",
              "6                                      O,O,O,O,O,O,O  \n",
              "7  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "8  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "9  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1585c83f-e9da-46d4-ba53-04b208ca9f97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>Experienced</td>\n",
              "      <td>O</td>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>staff</td>\n",
              "      <td>O</td>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>had</td>\n",
              "      <td>O</td>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>memorable</td>\n",
              "      <td>O</td>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 0</td>\n",
              "      <td>stay</td>\n",
              "      <td>O</td>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>India</td>\n",
              "      <td>O</td>\n",
              "      <td>India as a country has always fascinated me an...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>as</td>\n",
              "      <td>O</td>\n",
              "      <td>India as a country has always fascinated me an...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "      <td>India as a country has always fascinated me an...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1585c83f-e9da-46d4-ba53-04b208ca9f97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1585c83f-e9da-46d4-ba53-04b208ca9f97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1585c83f-e9da-46d4-ba53-04b208ca9f97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "E-rvxUqfAd0b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[3].sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IVFFBXKjA2_u",
        "outputId": "4b06ccd8-e6ab-475f-cd18-159c17c40daf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes , it really was a great experience and we visited various places but the most wonderful part of the trip was our stay at the Oberoi Udaivilas Luxury Hotel .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[3].word_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "n20ApNZ9A9_U",
        "outputId": "5a33a513-d3ed-4c36-e76c-034fd71d6ed0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-exp-Positive,I-exp-Positive,I-exp-Positive,I-exp-Positive,I-exp-Positive,I-exp-Positive,I-exp-Positive,O,O,O,O,B-targ-Positive,I-targ-Positive,I-targ-Positive,I-targ-Positive,I-targ-Positive,O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "XUjmY6al9Eiq",
        "outputId": "04ecde0f-b6de-4612-c82b-70175d5c9495"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0         Experienced staff and had a memorable stay   \n",
              "1  India as a country has always fascinated me an...   \n",
              "2  One of my friends who had been there before wa...   \n",
              "3  Yes , it really was a great experience and we ...   \n",
              "4  I can ’t explain in words how grand this place...   \n",
              "5  It is a unique blend of the old world royal ch...   \n",
              "6  I ’m definitely going there again whenever I g...   \n",
              "7                Bit pricey and but away from center   \n",
              "8  You need to count 20 · 30 minutes walking time...   \n",
              "9              There is no sauna nor swimming pool .   \n",
              "\n",
              "                                         word_labels  \n",
              "0                                      O,O,O,O,O,O,O  \n",
              "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "3  O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-exp-Positive,I-e...  \n",
              "4  O,O,O,O,O,O,B-exp-Positive,I-exp-Positive,B-ta...  \n",
              "5  B-targ-Positive,O,O,B-exp-Positive,I-exp-Posit...  \n",
              "6  B-holder,O,B-exp-Positive,I-exp-Positive,B-tar...  \n",
              "7  B-exp-Negative,I-exp-Negative,O,O,B-exp-Negati...  \n",
              "8  O,O,O,O,B-exp-Negative,I-exp-Negative,I-exp-Ne...  \n",
              "9  B-exp-Negative,I-exp-Negative,I-exp-Negative,B...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0643af88-1d1a-4a21-a260-201920dc077f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Experienced staff and had a memorable stay</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>India as a country has always fascinated me an...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One of my friends who had been there before wa...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes , it really was a great experience and we ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-exp-Positive,I-e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I can ’t explain in words how grand this place...</td>\n",
              "      <td>O,O,O,O,O,O,B-exp-Positive,I-exp-Positive,B-ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>It is a unique blend of the old world royal ch...</td>\n",
              "      <td>B-targ-Positive,O,O,B-exp-Positive,I-exp-Posit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I ’m definitely going there again whenever I g...</td>\n",
              "      <td>B-holder,O,B-exp-Positive,I-exp-Positive,B-tar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bit pricey and but away from center</td>\n",
              "      <td>B-exp-Negative,I-exp-Negative,O,O,B-exp-Negati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>You need to count 20 · 30 minutes walking time...</td>\n",
              "      <td>O,O,O,O,B-exp-Negative,I-exp-Negative,I-exp-Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>There is no sauna nor swimming pool .</td>\n",
              "      <td>B-exp-Negative,I-exp-Negative,I-exp-Negative,B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0643af88-1d1a-4a21-a260-201920dc077f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0643af88-1d1a-4a21-a260-201920dc077f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0643af88-1d1a-4a21-a260-201920dc077f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f\"Length of training data = {len(data)}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9UNaEetX9HYy",
        "outputId": "ef4ab074-4b98-4364-a0e6-92c641cdabe7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Length of training data = 1710'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MAX_LEN = 128\n",
        "# TRAIN_BATCH_SIZE = 32\n",
        "# VALID_BATCH_SIZE = 16\n",
        "# LEARNING_RATE = 1e-05\n",
        "# MAX_GRAD_NORM = 10\n",
        "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "r_dtUElsBAlY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "  # Takes pandas dataframe,tokenizer ,max_len as input\n",
        "  def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        sentence = self.data.sentence[index].strip().split()  \n",
        "        word_labels = self.data.word_labels[index].split(\",\") \n",
        "\n",
        "        # Using tokenizer to encode the sentence\n",
        "        # Padding of max_len is applied\n",
        "        encoding = self.tokenizer(sentence,\n",
        "                             is_pretokenized=True, \n",
        "                             return_offsets_mapping=True, \n",
        "                             padding='max_length', \n",
        "                             truncation=True, \n",
        "                             max_length=self.max_len)\n",
        "        \n",
        "\n",
        "        labels = [labels_to_ids[label] for label in word_labels] \n",
        "        # pad with -100\n",
        "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
        "        \n",
        "        # set only labels whose first offset position is 0 and the second is not 0\n",
        "        i = 0\n",
        "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "          if mapping[0] == 0 and mapping[1] != 0:\n",
        "            # overwrite label\n",
        "            encoded_labels[idx] = labels[i]\n",
        "            i += 1\n",
        "\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.as_tensor(encoded_labels)\n",
        "        \n",
        "        return item\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "HMFhfajqBapT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tUmheIgeHg6i"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "MAX_LEN = 128\n",
        "\n",
        "training_set = dataset(data, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "pAdX4qmRDTK9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0c88bfe1e7e34a2dbb963b8dc84135d9",
            "a4b2b4b6823849f885c76e599936fb66",
            "28ce04be0aa34815a8f4dad2e3889916",
            "25db5231d44248c084ab94aff58e98a0",
            "2eeb788b0360458fa4fa8484edafbdc0",
            "b6dbf880689d4d59af3cfd23a696b592",
            "05c8601b889f4dc9a8569e97f6ca1ab6",
            "688b390cf2e940939342d31d0ba4bebf",
            "001ad7132efd470c83b8071b2f6f1bd4",
            "a824b5e81c304964aabb17cc21830a8b",
            "2c03168979b8413599e288905e733c50"
          ]
        },
        "outputId": "f8b1ba48-03cf-48cc-d170-4a9874cbb128"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c88bfe1e7e34a2dbb963b8dc84135d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fyv-DLOYoz_W",
        "outputId": "7b58e90d-21d3-440d-ae88-51a64490732c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1710"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample output of one of the sentence from encoder block\n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[3][\"input_ids\"]), training_set[3][\"labels\"]):\n",
        "  print('{0:10}  {1}'.format(token, label))"
      ],
      "metadata": {
        "id": "bKbr0z5LK5oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f25e93-6541-4240-ab52-33ff57ef8d83"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]       -100\n",
            "yes         0\n",
            ",           0\n",
            "it          0\n",
            "really      0\n",
            "was         0\n",
            "a           0\n",
            "great       0\n",
            "experience  0\n",
            "and         0\n",
            "we          0\n",
            "visited     0\n",
            "various     0\n",
            "places      0\n",
            "but         0\n",
            "the         1\n",
            "most        2\n",
            "wonderful   2\n",
            "part        2\n",
            "of          2\n",
            "the         2\n",
            "trip        2\n",
            "was         0\n",
            "our         0\n",
            "stay        0\n",
            "at          0\n",
            "the         3\n",
            "obe         4\n",
            "##roi       -100\n",
            "ud          4\n",
            "##ai        -100\n",
            "##vil       -100\n",
            "##as        -100\n",
            "luxury      4\n",
            "hotel       4\n",
            ".           0\n",
            "[SEP]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n",
            "[PAD]       -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 10"
      ],
      "metadata": {
        "id": "_RZ19c04EzQa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n"
      ],
      "metadata": {
        "id": "ptLRSeiKLD_K"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zP5ONWt6LHed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c5b11b111f9f403a9d7f846fc9b3f10d",
            "4718a76e10d440f6a25b922dab5a76fb",
            "fa2a0b6e800343459266e09f2ad61277",
            "d87e8b82ac9f49f3aacd8ca7227f2713",
            "5876adb260b24dbdab6ec4a2e58ffc46",
            "1fb436f298ad49f4b7f0e51ff3010fa5",
            "d0021190cac5417d969dbec7c4446c2a",
            "d6be597dfeb8463c8cd47de177a21dae",
            "76537851e78c4071a6f90418b29ae8ae",
            "4281172bebc24ae4ba526060fd737196",
            "e7fa1626379f48838945160f6976b225",
            "5d57f6499dc34740b3334ad40970e4b5",
            "ce83f397ff9b4a4cb6c8aa6ee10166bb",
            "78246bf8c12147ba9193436944cb0c1d",
            "04d9b3f913cf44bf81ae8e8b36430e05",
            "bbc79c7d00474e25b83759ecd97808ff",
            "8efe0cb9c1da492aaba76ab19d977a92",
            "e68041c8c5044bfdb190c16c0fa6d451",
            "0fc1796ced9e46cf8981c396690886c7",
            "315ed0f5d173490e98b4d28aca6686d2",
            "6b6b23f121f847adb95b5aae915d3d98",
            "aea634c4c50b48caa10bbbe9ce299ba2"
          ]
        },
        "outputId": "aef8548e-44b4-451c-da63-6aefbe58a544"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5b11b111f9f403a9d7f846fc9b3f10d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d57f6499dc34740b3334ad40970e4b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "gkQ4l7QALeqt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        \n",
        "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        labels = batch['labels'].to(device, dtype = torch.long)\n",
        "\n",
        "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "        \n",
        "        if idx % 10==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 10 training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        \n",
        "        # only compute accuracy at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
        "        \n",
        "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_labels.extend(labels)\n",
        "        tr_preds.extend(predictions)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ],
      "metadata": {
        "id": "Hl373QxcLhUH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 8\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8Pi5rmVLlWL",
        "outputId": "168506f0-2431-49ed-cc3f-2dd48c8c84fa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 10 training steps: 2.5020554065704346\n",
            "Training loss per 10 training steps: 2.1852687922391025\n",
            "Training loss per 10 training steps: 1.9038052331833613\n",
            "Training loss per 10 training steps: 1.8061110127356745\n",
            "Training loss per 10 training steps: 1.7123832702636719\n",
            "Training loss per 10 training steps: 1.6440034193151138\n",
            "Training loss epoch: 1.6302900005269934\n",
            "Training accuracy epoch: 0.5450237363273696\n",
            "Training epoch: 2\n",
            "Training loss per 10 training steps: 1.4201716184616089\n",
            "Training loss per 10 training steps: 1.2861196886409412\n",
            "Training loss per 10 training steps: 1.316675101007734\n",
            "Training loss per 10 training steps: 1.292523730185724\n",
            "Training loss per 10 training steps: 1.2653509465659536\n",
            "Training loss per 10 training steps: 1.2448260760774799\n",
            "Training loss epoch: 1.2324174134819597\n",
            "Training accuracy epoch: 0.6291421479113211\n",
            "Training epoch: 3\n",
            "Training loss per 10 training steps: 0.977083146572113\n",
            "Training loss per 10 training steps: 1.0482358986681157\n",
            "Training loss per 10 training steps: 1.0097628746713911\n",
            "Training loss per 10 training steps: 1.0200130247300672\n",
            "Training loss per 10 training steps: 1.0140345401880217\n",
            "Training loss per 10 training steps: 0.9960762028600655\n",
            "Training loss epoch: 0.9884174631701576\n",
            "Training accuracy epoch: 0.686486016277679\n",
            "Training epoch: 4\n",
            "Training loss per 10 training steps: 1.0511717796325684\n",
            "Training loss per 10 training steps: 0.8736046661030162\n",
            "Training loss per 10 training steps: 0.8447355883462089\n",
            "Training loss per 10 training steps: 0.8254741814828688\n",
            "Training loss per 10 training steps: 0.8218049130788664\n",
            "Training loss per 10 training steps: 0.8054702165080052\n",
            "Training loss epoch: 0.8063483712849794\n",
            "Training accuracy epoch: 0.7372928881886684\n",
            "Training epoch: 5\n",
            "Training loss per 10 training steps: 0.6241562366485596\n",
            "Training loss per 10 training steps: 0.6954336870800365\n",
            "Training loss per 10 training steps: 0.6705325444539388\n",
            "Training loss per 10 training steps: 0.6585563901932009\n",
            "Training loss per 10 training steps: 0.6569701077007666\n",
            "Training loss per 10 training steps: 0.6629213474544824\n",
            "Training loss epoch: 0.6688487424894616\n",
            "Training accuracy epoch: 0.7805869920517359\n",
            "Training epoch: 6\n",
            "Training loss per 10 training steps: 0.608757495880127\n",
            "Training loss per 10 training steps: 0.563387854532762\n",
            "Training loss per 10 training steps: 0.563322785354796\n",
            "Training loss per 10 training steps: 0.5551819147602204\n",
            "Training loss per 10 training steps: 0.5497425278512443\n",
            "Training loss per 10 training steps: 0.5461641748746237\n",
            "Training loss epoch: 0.5480822733155003\n",
            "Training accuracy epoch: 0.8248593309288482\n",
            "Training epoch: 7\n",
            "Training loss per 10 training steps: 0.379285603761673\n",
            "Training loss per 10 training steps: 0.4764846861362457\n",
            "Training loss per 10 training steps: 0.4751235161508833\n",
            "Training loss per 10 training steps: 0.4654317036751778\n",
            "Training loss per 10 training steps: 0.4621695752550916\n",
            "Training loss per 10 training steps: 0.46552058937502844\n",
            "Training loss epoch: 0.46263744212962965\n",
            "Training accuracy epoch: 0.8522093139921159\n",
            "Training epoch: 8\n",
            "Training loss per 10 training steps: 0.41361308097839355\n",
            "Training loss per 10 training steps: 0.4323017651384527\n",
            "Training loss per 10 training steps: 0.3934514891533625\n",
            "Training loss per 10 training steps: 0.3878101898777869\n",
            "Training loss per 10 training steps: 0.3897997090002386\n",
            "Training loss per 10 training steps: 0.39221571122898774\n",
            "Training loss epoch: 0.39256710641913944\n",
            "Training accuracy epoch: 0.87319648229132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            labels = batch['labels'].to(device, dtype = torch.long)\n",
        "            \n",
        "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "        \n",
        "            if idx % 10==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 10 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            \n",
        "            # only compute accuracy at active labels\n",
        "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        \n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(labels)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
        "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "yXHkIpz8LoBI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation\n"
      ],
      "metadata": {
        "id": "oTL1mpzcnXzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('dev.json', encoding='utf-8') as inputfile:\n",
        "    df_dev = pd.read_json(inputfile,lines = True)\n",
        "\n",
        "\n",
        "\n",
        "with open('labeled_words_dev.csv', 'w', encoding='UTF8') as preproc_csv:\n",
        "    writer = csv.writer(preproc_csv)\n",
        "    writer.writerow(header)\n",
        "    for i in range(0, len(df_dev)):\n",
        "        n_words = len(df_dev['text'][i])\n",
        "        if(n_words == 0):\n",
        "            continue\n",
        "        for j in range(0, n_words):\n",
        "            token = \"O\"\n",
        "            if(len(df_dev['sources'][i][j]) > 1):\n",
        "                token = df_dev['sources'][i][j]\n",
        "            elif(len(df_dev['targets'][i][j]) > 1):\n",
        "                token = df_dev['targets'][i][j]\n",
        "            elif(len(df_dev['expressions'][i][j]) > 1):\n",
        "                token = df_dev['expressions'][i][j]\n",
        "            sentence_no = \"Sentence: \" + str(i)\n",
        "            \n",
        "            row = []\n",
        "            row.append(sentence_no)\n",
        "            row.append(df_dev['text'][i][j])\n",
        "            row.append(token)\n",
        "            writer.writerow(row)\n",
        "\n",
        "data_dev = pd.read_csv('labeled_words_dev.csv', encoding='UTF-8')\n",
        "\n",
        "\n",
        "# let's create a new column called \"sentence\" which groups the words by sentence \n",
        "data_dev['sentence'] = data_dev[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
        "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
        "data_dev['word_labels'] = data_dev[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
        "\n",
        "\n",
        "\n",
        "data_dev = data_dev[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
        "data_dev.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FDv8ZkxOR9GX",
        "outputId": "b2b40b2d-f63c-4e4e-f9bb-1e9a16ec35d5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  very warm welcome at the reception , very frie...   \n",
              "1                The room is very small , about 10m2   \n",
              "2  Hotel Premiere Classe Orly Rungis is near the ...   \n",
              "3  Near the hotel there is a bus stop that goes t...   \n",
              "4  In this area there is famous Rungis market , t...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  B-exp-Positive,I-exp-Positive,B-targ-Positive,...  \n",
              "1  B-targ-Negative,I-targ-Negative,O,B-exp-Negati...  \n",
              "2  B-targ-Negative,I-targ-Negative,I-targ-Negativ...  \n",
              "3  O,O,O,B-exp-Positive,I-exp-Positive,B-targ-Pos...  \n",
              "4  O,O,O,B-exp-Positive,I-exp-Positive,O,B-targ-P...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88653ff3-06e1-44c1-8da2-fb252f66b76e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>very warm welcome at the reception , very frie...</td>\n",
              "      <td>B-exp-Positive,I-exp-Positive,B-targ-Positive,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The room is very small , about 10m2</td>\n",
              "      <td>B-targ-Negative,I-targ-Negative,O,B-exp-Negati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hotel Premiere Classe Orly Rungis is near the ...</td>\n",
              "      <td>B-targ-Negative,I-targ-Negative,I-targ-Negativ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Near the hotel there is a bus stop that goes t...</td>\n",
              "      <td>O,O,O,B-exp-Positive,I-exp-Positive,B-targ-Pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In this area there is famous Rungis market , t...</td>\n",
              "      <td>O,O,O,B-exp-Positive,I-exp-Positive,O,B-targ-P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88653ff3-06e1-44c1-8da2-fb252f66b76e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88653ff3-06e1-44c1-8da2-fb252f66b76e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88653ff3-06e1-44c1-8da2-fb252f66b76e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_set = dataset(data_dev, tokenizer, MAX_LEN)\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "LjBMliWehRyp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(testing_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isjcZ-Xio6LA",
        "outputId": "bad0e590-e840-4887-94fd-53d449b2ef5e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "249"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfGQi4wFRgVi",
        "outputId": "9dd36b15-d6db-4ec3-9a28-6cdf9d813348"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 10 evaluation steps: 0.6322234272956848\n",
            "Validation loss per 10 evaluation steps: 0.8369430195201527\n",
            "Validation Loss: 0.7943809907883406\n",
            "Validation Accuracy: 0.762302514130975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Even though the price is decent for paris , I would not recommend this hotel .\""
      ],
      "metadata": {
        "id": "B0ryytK4R0xg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(sentence.split(),\n",
        "                    is_pretokenized=True, \n",
        "                    return_offsets_mapping=True, \n",
        "                    padding='max_length', \n",
        "                    truncation=True, \n",
        "                    max_length=MAX_LEN,\n",
        "                    return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, attention_mask=mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "prediction = []\n",
        "for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n",
        "  #only predictions on first word pieces are important\n",
        "  if mapping[0] == 0 and mapping[1] != 0:\n",
        "    prediction.append(token_pred[1])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print(sentence.split())\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEuKJlK3R5Xl",
        "outputId": "c8f79cf6-9807-4e50-e358-e9a3a1ea0250"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Even', 'though', 'the', 'price', 'is', 'decent', 'for', 'paris', ',', 'I', 'would', 'not', 'recommend', 'this', 'hotel', '.']\n",
            "['O', 'O', 'B-targ-Positive', 'I-targ-Positive', 'O', 'B-exp-Positive', 'O', 'O', 'O', 'B-holder', 'B-exp-Negative', 'B-exp-Negative', 'I-exp-Negative', 'B-targ-Negative', 'I-targ-Negative', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence[10:18])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLwgJ_bgvn01",
        "outputId": "7ff1777c-38da-4a78-c340-e3abb608b1c8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h the pr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "while i < len(prediction):\n",
        "  print(prediction[i])\n",
        "  i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b-zSOF6prEP",
        "outputId": "825b0730-6754-42e9-f334-8d11445a34c2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O\n",
            "O\n",
            "B-targ-Positive\n",
            "I-targ-Positive\n",
            "O\n",
            "B-exp-Positive\n",
            "O\n",
            "O\n",
            "O\n",
            "B-holder\n",
            "B-exp-Negative\n",
            "B-exp-Negative\n",
            "I-exp-Negative\n",
            "B-targ-Negative\n",
            "I-targ-Negative\n",
            "O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "holders = []\n",
        "holders_span = []\n",
        "pos_targets = []\n",
        "pos_targets_span = []\n",
        "neg_targets = []\n",
        "neg_targets_span = []\n",
        "pos_expressions = []\n",
        "pos_expressions_span = []\n",
        "neg_expressions = []\n",
        "neg_expressions_span = []\n",
        "\n",
        "n = len(prediction)\n",
        "words = sentence.split()\n",
        "i = 0\n",
        "curr_index = 0\n",
        "start_index = 0\n",
        "end_index = 0\n",
        "\n",
        "while i < n:\n",
        "  word = \"\" \n",
        "  if prediction[i][0] == 'O':\n",
        "    curr_index += len(words[i]) +1\n",
        "    i += 1\n",
        "   \n",
        "  elif prediction[i][0:5] == 'B-tar' and prediction[i][7] == 'P':\n",
        "    word = words[i]\n",
        "    start_index = curr_index\n",
        "    curr_index += len(words[i]) + 1\n",
        "    i += 1\n",
        "\n",
        "    while i < n and prediction[i][0:5] == 'I-tar' and prediction[i][7] == 'P':\n",
        "      word += \" \"\n",
        "      word += words[i]\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "    end_index = curr_index\n",
        "    sp = str(start_index) + \":\" + str(end_index-1)\n",
        "    pos_targets_span.append(sp)\n",
        "    pos_targets.append(word) \n",
        "\n",
        "  elif prediction[i][0:5] == 'B-tar' and prediction[i][7] == 'N':\n",
        "    word = words[i]\n",
        "    start_index = curr_index\n",
        "    curr_index += len(words[i]) + 1\n",
        "    i += 1\n",
        "\n",
        "    while i < n and prediction[i][0:5] == 'I-tar' and prediction[i][7] == 'N':\n",
        "      word += \" \"\n",
        "      word += words[i]\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "    end_index = curr_index\n",
        "    sp = str(start_index) + \":\" + str(end_index-1)\n",
        "    neg_targets_span.append(sp)\n",
        "    neg_targets.append(word) \n",
        "\n",
        "  elif prediction[i][0:5] == 'B-exp' and prediction[i][6] == 'P':\n",
        "    word = words[i]\n",
        "    start_index = curr_index\n",
        "    curr_index += len(words[i]) + 1\n",
        "    i += 1\n",
        "\n",
        "    while i < n and prediction[i][0:5] == 'I-exp' and prediction[i][6] == 'P':\n",
        "      word += \" \"\n",
        "      word += words[i]\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "    end_index = curr_index\n",
        "    sp = str(start_index) + \":\" + str(end_index-1)\n",
        "    pos_expressions_span.append(sp)\n",
        "    pos_expressions.append(word) \n",
        "\n",
        "  elif prediction[i][0:5] == 'B-exp' and prediction[i][6] == 'N':\n",
        "    word = words[i]\n",
        "    start_index = curr_index\n",
        "    curr_index += len(words[i]) + 1\n",
        "    i += 1\n",
        "\n",
        "    while i < n and prediction[i][0:5] == 'I-exp' and prediction[i][6] == 'N':\n",
        "      word += \" \"\n",
        "      word += words[i]\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "    end_index = curr_index\n",
        "    sp = str(start_index) + \":\" + str(end_index-1)\n",
        "    neg_expressions_span.append(sp)\n",
        "    neg_expressions.append(word) \n",
        "\n",
        "\n",
        "  elif prediction[i][0:5] == 'B-hol':\n",
        "    word = words[i]\n",
        "    start_index = curr_index\n",
        "    curr_index += len(words[i]) + 1\n",
        "    i += 1\n",
        "\n",
        "    while i < n and prediction[i][0:5] == 'I-hol':\n",
        "      word += \" \"\n",
        "      word += words[i]\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "    end_index = curr_index\n",
        "    sp = str(start_index) + \":\" + str(end_index-1)\n",
        "    holders_span.append(sp)\n",
        "    holders.append(word) \n",
        "\n",
        "  # curr_index += len(words[i]) + 1\n",
        "  # i += 1\n",
        "  \n",
        "\n",
        "print(holders , holders_span)\n",
        "print(pos_targets , pos_targets_span)\n",
        "print(neg_targets,neg_targets_span)\n",
        "print(pos_expressions,pos_expressions_span)\n",
        "print(neg_expressions,neg_expressions_span)\n",
        "\n",
        "# targets = pos_targets + neg_targets\n",
        "# expressions = pos_expressions + neg_expressions\n"
      ],
      "metadata": {
        "id": "tbOEJYQONc2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c2f957-7409-4b74-af02-f97baf901649"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I'] ['44:45']\n",
            "['the price'] ['12:21']\n",
            "['this hotel'] ['66:76']\n",
            "['decent'] ['25:31']\n",
            "['would', 'not recommend'] ['46:51', '52:65']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test.json', encoding='utf-8') as inputfile:\n",
        "    df = pd.read_json(inputfile,lines = True)\n"
      ],
      "metadata": {
        "id": "UKq7eCTZoEgI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(lst):\n",
        "  return ' '.join(lst)"
      ],
      "metadata": {
        "id": "VdB2Qu-tdWhl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwHlM76p51H9",
        "outputId": "c8f373e6-89f5-4a50-da62-db59ee675d16"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_list = []\n",
        "for w in range(0,len(df['text'])):\n",
        "  print(f\"Processing : {w}\")\n",
        "  words = df['text'][w]\n",
        "  inputs = tokenizer(words,\n",
        "                    is_pretokenized=True, \n",
        "                    return_offsets_mapping=True, \n",
        "                    padding='max_length', \n",
        "                    truncation=True, \n",
        "                    max_length=MAX_LEN,\n",
        "                    return_tensors=\"pt\")\n",
        "\n",
        "  # move to gpu\n",
        "  ids = inputs[\"input_ids\"].to(device)\n",
        "  mask = inputs[\"attention_mask\"].to(device)\n",
        "  # forward pass\n",
        "  outputs = model(ids, attention_mask=mask)\n",
        "  logits = outputs[0]\n",
        "\n",
        "  active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "  flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "  tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "  token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
        "  wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "  prediction = []\n",
        "  for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n",
        "    #only predictions on first word pieces are important\n",
        "    if mapping[0] == 0 and mapping[1] != 0:\n",
        "      prediction.append(token_pred[1])\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "\n",
        "  if w == 2 : \n",
        "    print(df['text'][w])\n",
        "    print(prediction)\n",
        "\n",
        "  holders = []\n",
        "  holders_span = []\n",
        "  pos_targets = []\n",
        "  pos_targets_span = []\n",
        "  neg_targets = []\n",
        "  neg_targets_span = []\n",
        "  pos_expressions = []\n",
        "  pos_expressions_span = []\n",
        "  neg_expressions = []\n",
        "  neg_expressions_span = []\n",
        "\n",
        "  n = len(prediction)\n",
        "  i = 0\n",
        "  curr_index = 0\n",
        "  start_index = 0\n",
        "  end_index = 0\n",
        "\n",
        "  while i < n:\n",
        "    word = \"\" \n",
        "    if prediction[i][0] == 'O':\n",
        "      curr_index += len(words[i]) +1\n",
        "      i += 1\n",
        "    \n",
        "    elif prediction[i][0:5] == 'B-tar' and prediction[i][7] == 'P':\n",
        "      word = words[i]\n",
        "      start_index = curr_index\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "\n",
        "      while i < n and prediction[i][0:5] == 'I-tar' and prediction[i][7] == 'P':\n",
        "        word += \" \"\n",
        "        word += words[i]\n",
        "        curr_index += len(words[i]) + 1\n",
        "        i += 1\n",
        "      end_index = curr_index\n",
        "      sp = str(start_index) + \":\" + str(end_index-1)\n",
        "      pos_targets_span.append(sp)\n",
        "      pos_targets.append(word) \n",
        "\n",
        "    elif prediction[i][0:5] == 'B-tar' and prediction[i][7] == 'N':\n",
        "      word = words[i]\n",
        "      start_index = curr_index\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "\n",
        "      while i < n and prediction[i][0:5] == 'I-tar' and prediction[i][7] == 'N':\n",
        "        word += \" \"\n",
        "        word += words[i]\n",
        "        curr_index += len(words[i]) + 1\n",
        "        i += 1\n",
        "      end_index = curr_index\n",
        "      sp = str(start_index) + \":\" + str(end_index-1)\n",
        "      neg_targets_span.append(sp)\n",
        "      neg_targets.append(word) \n",
        "\n",
        "    elif prediction[i][0:5] == 'B-exp' and prediction[i][6] == 'P':\n",
        "      word = words[i]\n",
        "      start_index = curr_index\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "\n",
        "      while i < n and prediction[i][0:5] == 'I-exp' and prediction[i][6] == 'P':\n",
        "        word += \" \"\n",
        "        word += words[i]\n",
        "        curr_index += len(words[i]) + 1\n",
        "        i += 1\n",
        "      end_index = curr_index\n",
        "      sp = str(start_index) + \":\" + str(end_index-1)\n",
        "      pos_expressions_span.append(sp)\n",
        "      pos_expressions.append(word) \n",
        "\n",
        "    elif prediction[i][0:5] == 'B-exp' and prediction[i][6] == 'N':\n",
        "      word = words[i]\n",
        "      start_index = curr_index\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "\n",
        "      while i < n and prediction[i][0:5] == 'I-exp' and prediction[i][6] == 'N':\n",
        "        word += \" \"\n",
        "        word += words[i]\n",
        "        curr_index += len(words[i]) + 1\n",
        "        i += 1\n",
        "      end_index = curr_index\n",
        "      sp = str(start_index) + \":\" + str(end_index-1)\n",
        "      neg_expressions_span.append(sp)\n",
        "      neg_expressions.append(word) \n",
        "\n",
        "\n",
        "    elif prediction[i][0:5] == 'B-hol':\n",
        "      word = words[i]\n",
        "      start_index = curr_index\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "\n",
        "      while i < n and prediction[i][0:5] == 'I-hol':\n",
        "        word += \" \"\n",
        "        word += words[i]\n",
        "        curr_index += len(words[i]) + 1\n",
        "        i += 1\n",
        "      end_index = curr_index\n",
        "      sp = str(start_index) + \":\" + str(end_index-1)\n",
        "      holders_span.append(sp)\n",
        "      holders.append(word)\n",
        "\n",
        "    else:\n",
        "      curr_index += len(words[i]) + 1\n",
        "      i += 1\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  dict1 = {\"sent_id\":df[\"sent_id\"][w] ,\"text\" : convert(df[\"text\"][w]),\"opinions\" : []}\n",
        "  for x in range(0,len(holders)):\n",
        "    for y in range(0,len(pos_expressions)):\n",
        "      for z in range(0,len(pos_targets)):\n",
        "        op_dict = {\"Source\":[[],[]] , \"Target\" : [[],[]],\"Polar_expression\" : [[],[]],\"Polarity\" : \"Positive\",\"Intensity\" : \"Standard\"}\n",
        "        op_dict[\"Source\"][0].append(holders[x])\n",
        "        op_dict[\"Source\"][1].append(holders_span[x])\n",
        "        op_dict[\"Polar_expression\"][0].append(pos_expressions[y])\n",
        "        op_dict[\"Polar_expression\"][1].append(pos_expressions_span[y])\n",
        "        op_dict[\"Target\"][0].append(pos_targets[z])\n",
        "        op_dict[\"Target\"][1].append(pos_targets_span[z])\n",
        "        dict1[\"opinions\"].append(op_dict)\n",
        "\n",
        "  for x in range(0,len(holders)):\n",
        "    for y in range(0,len(neg_expressions)):\n",
        "      for z in range(0,len(neg_targets)):\n",
        "        op_dict = {\"Source\":[[],[]] , \"Target\" : [[],[]],\"Polar_expression\" : [[],[]],\"Polarity\" : \"Negative\",\"Intensity\" : \"Standard\"}\n",
        "        op_dict[\"Source\"][0].append(holders[x])\n",
        "        op_dict[\"Source\"][1].append(holders_span[x])\n",
        "        op_dict[\"Polar_expression\"][0].append(neg_expressions[y])\n",
        "        op_dict[\"Polar_expression\"][1].append(neg_expressions_span[y])\n",
        "        op_dict[\"Target\"][0].append(neg_targets[z])\n",
        "        op_dict[\"Target\"][1].append(neg_targets_span[z])\n",
        "        dict1[\"opinions\"].append(op_dict)\n",
        "  \n",
        "  dict_list.append(dict1)\n",
        "\n"
      ],
      "metadata": {
        "id": "MKxM2Eh09-FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595d51c7-b1a0-461e-f0e2-7ac4510e2100"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing : 0\n",
            "Processing : 1\n",
            "Processing : 2\n",
            "['A', 'wonderful', 'place', 'to', 'go', 'and', 'we', 'are', 'planning', 'to', 'return', 'as', 'soon', 'as', 'we', 'can', '.']\n",
            "['O', 'B-exp-Positive', 'B-targ-Positive', 'O', 'I-exp-Positive', 'O', 'B-holder', 'O', 'B-exp-Positive', 'I-exp-Positive', 'I-exp-Positive', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Processing : 3\n",
            "Processing : 4\n",
            "Processing : 5\n",
            "Processing : 6\n",
            "Processing : 7\n",
            "Processing : 8\n",
            "Processing : 9\n",
            "Processing : 10\n",
            "Processing : 11\n",
            "Processing : 12\n",
            "Processing : 13\n",
            "Processing : 14\n",
            "Processing : 15\n",
            "Processing : 16\n",
            "Processing : 17\n",
            "Processing : 18\n",
            "Processing : 19\n",
            "Processing : 20\n",
            "Processing : 21\n",
            "Processing : 22\n",
            "Processing : 23\n",
            "Processing : 24\n",
            "Processing : 25\n",
            "Processing : 26\n",
            "Processing : 27\n",
            "Processing : 28\n",
            "Processing : 29\n",
            "Processing : 30\n",
            "Processing : 31\n",
            "Processing : 32\n",
            "Processing : 33\n",
            "Processing : 34\n",
            "Processing : 35\n",
            "Processing : 36\n",
            "Processing : 37\n",
            "Processing : 38\n",
            "Processing : 39\n",
            "Processing : 40\n",
            "Processing : 41\n",
            "Processing : 42\n",
            "Processing : 43\n",
            "Processing : 44\n",
            "Processing : 45\n",
            "Processing : 46\n",
            "Processing : 47\n",
            "Processing : 48\n",
            "Processing : 49\n",
            "Processing : 50\n",
            "Processing : 51\n",
            "Processing : 52\n",
            "Processing : 53\n",
            "Processing : 54\n",
            "Processing : 55\n",
            "Processing : 56\n",
            "Processing : 57\n",
            "Processing : 58\n",
            "Processing : 59\n",
            "Processing : 60\n",
            "Processing : 61\n",
            "Processing : 62\n",
            "Processing : 63\n",
            "Processing : 64\n",
            "Processing : 65\n",
            "Processing : 66\n",
            "Processing : 67\n",
            "Processing : 68\n",
            "Processing : 69\n",
            "Processing : 70\n",
            "Processing : 71\n",
            "Processing : 72\n",
            "Processing : 73\n",
            "Processing : 74\n",
            "Processing : 75\n",
            "Processing : 76\n",
            "Processing : 77\n",
            "Processing : 78\n",
            "Processing : 79\n",
            "Processing : 80\n",
            "Processing : 81\n",
            "Processing : 82\n",
            "Processing : 83\n",
            "Processing : 84\n",
            "Processing : 85\n",
            "Processing : 86\n",
            "Processing : 87\n",
            "Processing : 88\n",
            "Processing : 89\n",
            "Processing : 90\n",
            "Processing : 91\n",
            "Processing : 92\n",
            "Processing : 93\n",
            "Processing : 94\n",
            "Processing : 95\n",
            "Processing : 96\n",
            "Processing : 97\n",
            "Processing : 98\n",
            "Processing : 99\n",
            "Processing : 100\n",
            "Processing : 101\n",
            "Processing : 102\n",
            "Processing : 103\n",
            "Processing : 104\n",
            "Processing : 105\n",
            "Processing : 106\n",
            "Processing : 107\n",
            "Processing : 108\n",
            "Processing : 109\n",
            "Processing : 110\n",
            "Processing : 111\n",
            "Processing : 112\n",
            "Processing : 113\n",
            "Processing : 114\n",
            "Processing : 115\n",
            "Processing : 116\n",
            "Processing : 117\n",
            "Processing : 118\n",
            "Processing : 119\n",
            "Processing : 120\n",
            "Processing : 121\n",
            "Processing : 122\n",
            "Processing : 123\n",
            "Processing : 124\n",
            "Processing : 125\n",
            "Processing : 126\n",
            "Processing : 127\n",
            "Processing : 128\n",
            "Processing : 129\n",
            "Processing : 130\n",
            "Processing : 131\n",
            "Processing : 132\n",
            "Processing : 133\n",
            "Processing : 134\n",
            "Processing : 135\n",
            "Processing : 136\n",
            "Processing : 137\n",
            "Processing : 138\n",
            "Processing : 139\n",
            "Processing : 140\n",
            "Processing : 141\n",
            "Processing : 142\n",
            "Processing : 143\n",
            "Processing : 144\n",
            "Processing : 145\n",
            "Processing : 146\n",
            "Processing : 147\n",
            "Processing : 148\n",
            "Processing : 149\n",
            "Processing : 150\n",
            "Processing : 151\n",
            "Processing : 152\n",
            "Processing : 153\n",
            "Processing : 154\n",
            "Processing : 155\n",
            "Processing : 156\n",
            "Processing : 157\n",
            "Processing : 158\n",
            "Processing : 159\n",
            "Processing : 160\n",
            "Processing : 161\n",
            "Processing : 162\n",
            "Processing : 163\n",
            "Processing : 164\n",
            "Processing : 165\n",
            "Processing : 166\n",
            "Processing : 167\n",
            "Processing : 168\n",
            "Processing : 169\n",
            "Processing : 170\n",
            "Processing : 171\n",
            "Processing : 172\n",
            "Processing : 173\n",
            "Processing : 174\n",
            "Processing : 175\n",
            "Processing : 176\n",
            "Processing : 177\n",
            "Processing : 178\n",
            "Processing : 179\n",
            "Processing : 180\n",
            "Processing : 181\n",
            "Processing : 182\n",
            "Processing : 183\n",
            "Processing : 184\n",
            "Processing : 185\n",
            "Processing : 186\n",
            "Processing : 187\n",
            "Processing : 188\n",
            "Processing : 189\n",
            "Processing : 190\n",
            "Processing : 191\n",
            "Processing : 192\n",
            "Processing : 193\n",
            "Processing : 194\n",
            "Processing : 195\n",
            "Processing : 196\n",
            "Processing : 197\n",
            "Processing : 198\n",
            "Processing : 199\n",
            "Processing : 200\n",
            "Processing : 201\n",
            "Processing : 202\n",
            "Processing : 203\n",
            "Processing : 204\n",
            "Processing : 205\n",
            "Processing : 206\n",
            "Processing : 207\n",
            "Processing : 208\n",
            "Processing : 209\n",
            "Processing : 210\n",
            "Processing : 211\n",
            "Processing : 212\n",
            "Processing : 213\n",
            "Processing : 214\n",
            "Processing : 215\n",
            "Processing : 216\n",
            "Processing : 217\n",
            "Processing : 218\n",
            "Processing : 219\n",
            "Processing : 220\n",
            "Processing : 221\n",
            "Processing : 222\n",
            "Processing : 223\n",
            "Processing : 224\n",
            "Processing : 225\n",
            "Processing : 226\n",
            "Processing : 227\n",
            "Processing : 228\n",
            "Processing : 229\n",
            "Processing : 230\n",
            "Processing : 231\n",
            "Processing : 232\n",
            "Processing : 233\n",
            "Processing : 234\n",
            "Processing : 235\n",
            "Processing : 236\n",
            "Processing : 237\n",
            "Processing : 238\n",
            "Processing : 239\n",
            "Processing : 240\n",
            "Processing : 241\n",
            "Processing : 242\n",
            "Processing : 243\n",
            "Processing : 244\n",
            "Processing : 245\n",
            "Processing : 246\n",
            "Processing : 247\n",
            "Processing : 248\n",
            "Processing : 249\n",
            "Processing : 250\n",
            "Processing : 251\n",
            "Processing : 252\n",
            "Processing : 253\n",
            "Processing : 254\n",
            "Processing : 255\n",
            "Processing : 256\n",
            "Processing : 257\n",
            "Processing : 258\n",
            "Processing : 259\n",
            "Processing : 260\n",
            "Processing : 261\n",
            "Processing : 262\n",
            "Processing : 263\n",
            "Processing : 264\n",
            "Processing : 265\n",
            "Processing : 266\n",
            "Processing : 267\n",
            "Processing : 268\n",
            "Processing : 269\n",
            "Processing : 270\n",
            "Processing : 271\n",
            "Processing : 272\n",
            "Processing : 273\n",
            "Processing : 274\n",
            "Processing : 275\n",
            "Processing : 276\n",
            "Processing : 277\n",
            "Processing : 278\n",
            "Processing : 279\n",
            "Processing : 280\n",
            "Processing : 281\n",
            "Processing : 282\n",
            "Processing : 283\n",
            "Processing : 284\n",
            "Processing : 285\n",
            "Processing : 286\n",
            "Processing : 287\n",
            "Processing : 288\n",
            "Processing : 289\n",
            "Processing : 290\n",
            "Processing : 291\n",
            "Processing : 292\n",
            "Processing : 293\n",
            "Processing : 294\n",
            "Processing : 295\n",
            "Processing : 296\n",
            "Processing : 297\n",
            "Processing : 298\n",
            "Processing : 299\n",
            "Processing : 300\n",
            "Processing : 301\n",
            "Processing : 302\n",
            "Processing : 303\n",
            "Processing : 304\n",
            "Processing : 305\n",
            "Processing : 306\n",
            "Processing : 307\n",
            "Processing : 308\n",
            "Processing : 309\n",
            "Processing : 310\n",
            "Processing : 311\n",
            "Processing : 312\n",
            "Processing : 313\n",
            "Processing : 314\n",
            "Processing : 315\n",
            "Processing : 316\n",
            "Processing : 317\n",
            "Processing : 318\n",
            "Processing : 319\n",
            "Processing : 320\n",
            "Processing : 321\n",
            "Processing : 322\n",
            "Processing : 323\n",
            "Processing : 324\n",
            "Processing : 325\n",
            "Processing : 326\n",
            "Processing : 327\n",
            "Processing : 328\n",
            "Processing : 329\n",
            "Processing : 330\n",
            "Processing : 331\n",
            "Processing : 332\n",
            "Processing : 333\n",
            "Processing : 334\n",
            "Processing : 335\n",
            "Processing : 336\n",
            "Processing : 337\n",
            "Processing : 338\n",
            "Processing : 339\n",
            "Processing : 340\n",
            "Processing : 341\n",
            "Processing : 342\n",
            "Processing : 343\n",
            "Processing : 344\n",
            "Processing : 345\n",
            "Processing : 346\n",
            "Processing : 347\n",
            "Processing : 348\n",
            "Processing : 349\n",
            "Processing : 350\n",
            "Processing : 351\n",
            "Processing : 352\n",
            "Processing : 353\n",
            "Processing : 354\n",
            "Processing : 355\n",
            "Processing : 356\n",
            "Processing : 357\n",
            "Processing : 358\n",
            "Processing : 359\n",
            "Processing : 360\n",
            "Processing : 361\n",
            "Processing : 362\n",
            "Processing : 363\n",
            "Processing : 364\n",
            "Processing : 365\n",
            "Processing : 366\n",
            "Processing : 367\n",
            "Processing : 368\n",
            "Processing : 369\n",
            "Processing : 370\n",
            "Processing : 371\n",
            "Processing : 372\n",
            "Processing : 373\n",
            "Processing : 374\n",
            "Processing : 375\n",
            "Processing : 376\n",
            "Processing : 377\n",
            "Processing : 378\n",
            "Processing : 379\n",
            "Processing : 380\n",
            "Processing : 381\n",
            "Processing : 382\n",
            "Processing : 383\n",
            "Processing : 384\n",
            "Processing : 385\n",
            "Processing : 386\n",
            "Processing : 387\n",
            "Processing : 388\n",
            "Processing : 389\n",
            "Processing : 390\n",
            "Processing : 391\n",
            "Processing : 392\n",
            "Processing : 393\n",
            "Processing : 394\n",
            "Processing : 395\n",
            "Processing : 396\n",
            "Processing : 397\n",
            "Processing : 398\n",
            "Processing : 399\n",
            "Processing : 400\n",
            "Processing : 401\n",
            "Processing : 402\n",
            "Processing : 403\n",
            "Processing : 404\n",
            "Processing : 405\n",
            "Processing : 406\n",
            "Processing : 407\n",
            "Processing : 408\n",
            "Processing : 409\n",
            "Processing : 410\n",
            "Processing : 411\n",
            "Processing : 412\n",
            "Processing : 413\n",
            "Processing : 414\n",
            "Processing : 415\n",
            "Processing : 416\n",
            "Processing : 417\n",
            "Processing : 418\n",
            "Processing : 419\n",
            "Processing : 420\n",
            "Processing : 421\n",
            "Processing : 422\n",
            "Processing : 423\n",
            "Processing : 424\n",
            "Processing : 425\n",
            "Processing : 426\n",
            "Processing : 427\n",
            "Processing : 428\n",
            "Processing : 429\n",
            "Processing : 430\n",
            "Processing : 431\n",
            "Processing : 432\n",
            "Processing : 433\n",
            "Processing : 434\n",
            "Processing : 435\n",
            "Processing : 436\n",
            "Processing : 437\n",
            "Processing : 438\n",
            "Processing : 439\n",
            "Processing : 440\n",
            "Processing : 441\n",
            "Processing : 442\n",
            "Processing : 443\n",
            "Processing : 444\n",
            "Processing : 445\n",
            "Processing : 446\n",
            "Processing : 447\n",
            "Processing : 448\n",
            "Processing : 449\n",
            "Processing : 450\n",
            "Processing : 451\n",
            "Processing : 452\n",
            "Processing : 453\n",
            "Processing : 454\n",
            "Processing : 455\n",
            "Processing : 456\n",
            "Processing : 457\n",
            "Processing : 458\n",
            "Processing : 459\n",
            "Processing : 460\n",
            "Processing : 461\n",
            "Processing : 462\n",
            "Processing : 463\n",
            "Processing : 464\n",
            "Processing : 465\n",
            "Processing : 466\n",
            "Processing : 467\n",
            "Processing : 468\n",
            "Processing : 469\n",
            "Processing : 470\n",
            "Processing : 471\n",
            "Processing : 472\n",
            "Processing : 473\n",
            "Processing : 474\n",
            "Processing : 475\n",
            "Processing : 476\n",
            "Processing : 477\n",
            "Processing : 478\n",
            "Processing : 479\n",
            "Processing : 480\n",
            "Processing : 481\n",
            "Processing : 482\n",
            "Processing : 483\n",
            "Processing : 484\n",
            "Processing : 485\n",
            "Processing : 486\n",
            "Processing : 487\n",
            "Processing : 488\n",
            "Processing : 489\n",
            "Processing : 490\n",
            "Processing : 491\n",
            "Processing : 492\n",
            "Processing : 493\n",
            "Processing : 494\n",
            "Processing : 495\n",
            "Processing : 496\n",
            "Processing : 497\n",
            "Processing : 498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json_object = json.dumps(dict_list)\n",
        "with open(\"predictions.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)\n",
        "outfile.close()"
      ],
      "metadata": {
        "id": "amYDW-h0N7wI"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check(list1,list2):\n",
        "  if(len(list1) != len(list2)):\n",
        "    return False\n",
        "  else:\n",
        "    for i in range(len(list1)):\n",
        "      flag = 0\n",
        "      for j in range(len(list2)):\n",
        "        if list1[i] == list2[j]:\n",
        "          flag = 1\n",
        "      if(flag == 0):\n",
        "        return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "s5FoE6mCMNtJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Calc_accuracy(gold_tuples,predicted_tuples):\n",
        "  correct_values = 0\n",
        "  for w in range(0,len(gold_tuples)):\n",
        "    if gold_tuples[w]['sent_id'] == predicted_tuples[w]['sent_id']:\n",
        "      if len(gold_tuples[w]['opinions']) != len(predicted_tuples[w]['opinions']):\n",
        "        continue\n",
        "      else:\n",
        "        for i in range(0,len(gold_tuples[w]['opinions'])):\n",
        "          flag = 0\n",
        "          for j in range(0,len(predicted_tuples[w]['opinions'])):\n",
        "            if check(gold_tuples[w]['opinions'][i][\"Source\"],predicted_tuples[w]['opinions'][j][\"Source\"]) and check(gold_tuples[w]['opinions'][i][\"Target\"],predicted_tuples[w]['opinions'][j][\"Target\"]) and check(gold_tuples[w]['opinions'][i][\"Polar_expression\"],predicted_tuples[w]['opinions'][j][\"Polar_expression\"]) :\n",
        "              correct_values += 1\n",
        "  return correct_values"
      ],
      "metadata": {
        "id": "kHmLDDKGJEPw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gold_test.json', encoding='utf-8') as inputfile:\n",
        "  gold_df = json.load(inputfile)\n",
        "with open('predictions.json', encoding='utf-8') as inpfile:\n",
        "  predicted_df = json.load(inpfile)\n",
        "\n",
        "# print(gold_df)\n",
        "print(gold_df[0])\n",
        "print(gold_df[1])\n",
        "print(Calc_accuracy(gold_df,predicted_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wki2JQRoJyyy",
        "outputId": "a1221c16-0b48-42a4-af48-d9ace284fba3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sent_id': 'opener_en/kaf/hotel/english00148_ddb06f1e4ab012d85f9120c394168c48-5', 'text': 'So wonderful to see people go to work smiling and leave work still smiling and happy .', 'opinions': []}\n",
            "{'sent_id': 'opener_en/kaf/hotel/english00148_ddb06f1e4ab012d85f9120c394168c48-6', 'text': 'They were there just to keep us happy .', 'opinions': [{'Source': [['us'], ['29:31']], 'Target': [['They'], ['0:4']], 'Polar_expression': [['to keep', 'happy'], ['21:28', '32:37']], 'Polarity': 'Positive', 'Intensity': 'Standard'}]}\n",
            "7\n"
          ]
        }
      ]
    }
  ]
}